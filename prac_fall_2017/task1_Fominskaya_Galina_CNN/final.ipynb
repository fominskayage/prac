{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Московский Государственный Университет имени М.В. Ломоносова \n",
    "\n",
    "Факультет вычислительной математики и кибернетики \n",
    "\n",
    "Фоминская Галина\n",
    "\n",
    "кафедра ММП, группа 317\n",
    "\n",
    "2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свёрточные автокодировщики для улучшения качества классификации изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе был проведен анализ задач классификации изображений с помощью свёрточной нейронной сети. Для реализации классов свёрточной нейронной сети и свёрточного автокодировщика использовалась библиотека pytorch. Эксперименты были проведены на датасетe stl-10. В качестве мер качества использовались accuracy и log loss. Также были рассмотрены решения задачи классификации изображений с использованием метода мультиномиальной регрессии и метода RandomForest, а также сравнение качества работы этих методов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение необходимых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conv' from '/Users/Galya/Documents/studying/6th_semester/prac/task_1/conv.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conv\n",
    "from importlib import reload\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import timeit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline\n",
    "reload(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных\n",
    "В датасете stl-10 есть обучающая, тестовая и неразмеченная выборки. Обучающая выборка использовалась для тренировки моделей для классификации, а неразмеченная - для обучения автоэнкодера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(size=(32, 32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.STL10(root='./data', split='train',\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.STL10(root='./data', split='test',\n",
    "                                       download=False, transform=transform)\n",
    "\n",
    "unlabeledset = torchvision.datasets.STL10(root='./data', split='unlabeled',\n",
    "                                       download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "unlabeledloader = torch.utils.data.DataLoader(unlabeledset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Мультиномиальная регрессия и деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Multinomial(nn.Module):\n",
    "    def __init__(self, input_size=3 * 32 * 32):\n",
    "        super(Multinomial, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mult = Multinomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mult.parameters(), lr=0.001, weight_decay=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.968\n",
      "[2,  1000] loss: 1.815\n",
      "[3,  1000] loss: 1.741\n",
      "[4,  1000] loss: 1.720\n",
      "[5,  1000] loss: 1.673\n",
      "[6,  1000] loss: 1.658\n",
      "[7,  1000] loss: 1.631\n",
      "[8,  1000] loss: 1.606\n",
      "[9,  1000] loss: 1.578\n",
      "[10,  1000] loss: 1.591\n",
      "[11,  1000] loss: 1.561\n",
      "[12,  1000] loss: 1.549\n",
      "[13,  1000] loss: 1.535\n",
      "[14,  1000] loss: 1.528\n",
      "[15,  1000] loss: 1.525\n",
      "[16,  1000] loss: 1.496\n",
      "[17,  1000] loss: 1.496\n",
      "[18,  1000] loss: 1.488\n",
      "[19,  1000] loss: 1.478\n",
      "[20,  1000] loss: 1.457\n",
      "[21,  1000] loss: 1.460\n",
      "[22,  1000] loss: 1.447\n",
      "[23,  1000] loss: 1.438\n",
      "[24,  1000] loss: 1.432\n",
      "[25,  1000] loss: 1.427\n",
      "[26,  1000] loss: 1.421\n",
      "[27,  1000] loss: 1.415\n",
      "[28,  1000] loss: 1.410\n",
      "[29,  1000] loss: 1.396\n",
      "[30,  1000] loss: 1.381\n",
      "[31,  1000] loss: 1.381\n",
      "[32,  1000] loss: 1.369\n",
      "[33,  1000] loss: 1.364\n",
      "[34,  1000] loss: 1.369\n",
      "[35,  1000] loss: 1.351\n",
      "[36,  1000] loss: 1.361\n",
      "[37,  1000] loss: 1.357\n",
      "[38,  1000] loss: 1.331\n",
      "[39,  1000] loss: 1.343\n",
      "[40,  1000] loss: 1.340\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mult(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images: 36 %\n",
      "Log-loss of the network on the 8000 test images:  0.45098293489590285\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = mult(Variable(images))\n",
    "    loss = criterion(outputs, Variable(labels))\n",
    "    running_loss += loss.data[0]\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 8000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Log-loss of the network on the 8000 test images: ',\n",
    "    running_loss / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    X_tmp, y_tmp = data\n",
    "    for elem in y_tmp:\n",
    "        y_train.append(elem)\n",
    "\n",
    "    tmp = np.array(X_tmp.view(4, 3 * 32 * 32))\n",
    "    if type(X_train) is list:\n",
    "        X_train = tmp\n",
    "    else:\n",
    "        X_train = np.vstack((X_train, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images: 34 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "for data in testloader:\n",
    "    X_test, y_test = data\n",
    "    X_test = X_test.view(-1, 3 * 32 * 32)\n",
    "    outputs = clf.predict(np.array(X_test))\n",
    "    total += y_test.size(0)\n",
    "    correct += (outputs == y_test).sum()\n",
    "\n",
    "\n",
    "print('Accuracy of the network on the 8000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, мультиномиальная регрессия дает на тестовых данных качество 36%, а алгоритм RandomForest 34%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сверточная нейронная сеть  \n",
    "\n",
    "Посмотрим, какое качество классификации нам удастся получить, настраивая параметры сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем размер ядра свёртки (небольшие значения, от 2 до 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv kernel size:  2\n",
      "[1,  1000] loss: 2.063\n",
      "[2,  1000] loss: 1.722\n",
      "[3,  1000] loss: 1.548\n",
      "[4,  1000] loss: 1.409\n",
      "[5,  1000] loss: 1.289\n",
      "[6,  1000] loss: 1.171\n",
      "[7,  1000] loss: 1.074\n",
      "[8,  1000] loss: 0.965\n",
      "[9,  1000] loss: 0.864\n",
      "[10,  1000] loss: 0.747\n",
      "[11,  1000] loss: 0.627\n",
      "[12,  1000] loss: 0.530\n",
      "[13,  1000] loss: 0.409\n",
      "[14,  1000] loss: 0.306\n",
      "[15,  1000] loss: 0.235\n",
      "[16,  1000] loss: 0.238\n",
      "[17,  1000] loss: 0.179\n",
      "[18,  1000] loss: 0.097\n",
      "[19,  1000] loss: 0.070\n",
      "[20,  1000] loss: 0.116\n",
      "[21,  1000] loss: 0.083\n",
      "[22,  1000] loss: 0.085\n",
      "[23,  1000] loss: 0.054\n",
      "[24,  1000] loss: 0.013\n",
      "[25,  1000] loss: 0.017\n",
      "[26,  1000] loss: 0.002\n",
      "[27,  1000] loss: 0.002\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 189\n",
      "Accuracy of the network on the 80000 test images: 53 %\n",
      "Conv kernel size:  4\n",
      "[1,  1000] loss: 2.021\n",
      "[2,  1000] loss: 1.641\n",
      "[3,  1000] loss: 1.460\n",
      "[4,  1000] loss: 1.325\n",
      "[5,  1000] loss: 1.216\n",
      "[6,  1000] loss: 1.119\n",
      "[7,  1000] loss: 1.001\n",
      "[8,  1000] loss: 0.900\n",
      "[9,  1000] loss: 0.798\n",
      "[10,  1000] loss: 0.674\n",
      "[11,  1000] loss: 0.581\n",
      "[12,  1000] loss: 0.471\n",
      "[13,  1000] loss: 0.358\n",
      "[14,  1000] loss: 0.273\n",
      "[15,  1000] loss: 0.219\n",
      "[16,  1000] loss: 0.259\n",
      "[17,  1000] loss: 0.188\n",
      "[18,  1000] loss: 0.123\n",
      "[19,  1000] loss: 0.104\n",
      "[20,  1000] loss: 0.115\n",
      "[21,  1000] loss: 0.092\n",
      "[22,  1000] loss: 0.088\n",
      "[23,  1000] loss: 0.061\n",
      "[24,  1000] loss: 0.014\n",
      "[25,  1000] loss: 0.003\n",
      "[26,  1000] loss: 0.002\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 175\n",
      "Accuracy of the network on the 80000 test images: 53 %\n",
      "Conv kernel size:  6\n",
      "[1,  1000] loss: 2.036\n",
      "[2,  1000] loss: 1.657\n",
      "[3,  1000] loss: 1.491\n",
      "[4,  1000] loss: 1.373\n",
      "[5,  1000] loss: 1.269\n",
      "[6,  1000] loss: 1.181\n",
      "[7,  1000] loss: 1.060\n",
      "[8,  1000] loss: 0.958\n",
      "[9,  1000] loss: 0.844\n",
      "[10,  1000] loss: 0.699\n",
      "[11,  1000] loss: 0.595\n",
      "[12,  1000] loss: 0.499\n",
      "[13,  1000] loss: 0.382\n",
      "[14,  1000] loss: 0.331\n",
      "[15,  1000] loss: 0.285\n",
      "[16,  1000] loss: 0.265\n",
      "[17,  1000] loss: 0.181\n",
      "[18,  1000] loss: 0.130\n",
      "[19,  1000] loss: 0.122\n",
      "[20,  1000] loss: 0.165\n",
      "[21,  1000] loss: 0.152\n",
      "[22,  1000] loss: 0.137\n",
      "[23,  1000] loss: 0.084\n",
      "[24,  1000] loss: 0.034\n",
      "[25,  1000] loss: 0.007\n",
      "[26,  1000] loss: 0.003\n",
      "[27,  1000] loss: 0.002\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 159\n",
      "Accuracy of the network on the 80000 test images: 52 %\n",
      "Conv kernel size:  8\n",
      "[1,  1000] loss: 2.058\n",
      "[2,  1000] loss: 1.662\n",
      "[3,  1000] loss: 1.510\n",
      "[4,  1000] loss: 1.406\n",
      "[5,  1000] loss: 1.320\n",
      "[6,  1000] loss: 1.219\n",
      "[7,  1000] loss: 1.121\n",
      "[8,  1000] loss: 1.027\n",
      "[9,  1000] loss: 0.926\n",
      "[10,  1000] loss: 0.821\n",
      "[11,  1000] loss: 0.715\n",
      "[12,  1000] loss: 0.646\n",
      "[13,  1000] loss: 0.536\n",
      "[14,  1000] loss: 0.445\n",
      "[15,  1000] loss: 0.401\n",
      "[16,  1000] loss: 0.272\n",
      "[17,  1000] loss: 0.289\n",
      "[18,  1000] loss: 0.256\n",
      "[19,  1000] loss: 0.193\n",
      "[20,  1000] loss: 0.181\n",
      "[21,  1000] loss: 0.147\n",
      "[22,  1000] loss: 0.207\n",
      "[23,  1000] loss: 0.175\n",
      "[24,  1000] loss: 0.123\n",
      "[25,  1000] loss: 0.131\n",
      "[26,  1000] loss: 0.111\n",
      "[27,  1000] loss: 0.142\n",
      "[28,  1000] loss: 0.088\n",
      "[29,  1000] loss: 0.044\n",
      "[30,  1000] loss: 0.021\n",
      "Time: 152\n",
      "Accuracy of the network on the 80000 test images: 49 %\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "for conv1_kernel_size in range(2, 10, 2):\n",
    "    loss_tmp = []\n",
    "    print('Conv kernel size: ', conv1_kernel_size)\n",
    "    net = ConvNet(conv1_kernel_size=conv1_kernel_size, \\\n",
    "                      conv1_out_channels=20, \\\n",
    "                      layers_num=1)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(30):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 1000 == 999:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                loss_tmp.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "    losses.append(loss_tmp)\n",
    "    print('Time: %d' % (timeit.default_timer() - start_time))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "    print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3dc3ef0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhHKueQu+ZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124f902e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(30), losses[1])\n",
    "#plt.plot(range(30), losses[1])\n",
    "#plt.plot(range(30), losses[2])\n",
    "#plt.plot(range(30), losses[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{table}[!h]\n",
    "    \\begin{center}\n",
    "    \\caption{kernel size}\n",
    "    \\begin{tabular}{|c|c|c|c|c|}\n",
    "        \\hline  \\bf{kernel size} & \\bf{time (s)}  & \\bf{accuracy (\\%)}  \\\\ \\hline\n",
    "        2 & 189  & \\bf{53} \\\\ \\hline\n",
    "        4 & 175  & \\bf{53} \\\\ \\hline\n",
    "        6 & 159 &  52 \\\\ \\hline\n",
    "        8 & \\bf{152} &  49 \\\\ \\hline\n",
    "    \\end{tabular}\n",
    "\n",
    "    \\label{kernelsize}\n",
    "    \\end{center}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что лучшее значение accuracy и лучшее время получается при размере ядра свертки 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем количество фильтров на свёрточном слое (достаточно больше значения, от 5 до 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv out channels:  5\n",
      "[1,  1000] loss: 2.191\n",
      "[2,  1000] loss: 1.768\n",
      "[3,  1000] loss: 1.600\n",
      "[4,  1000] loss: 1.472\n",
      "[5,  1000] loss: 1.364\n",
      "[6,  1000] loss: 1.287\n",
      "[7,  1000] loss: 1.186\n",
      "[8,  1000] loss: 1.108\n",
      "[9,  1000] loss: 1.016\n",
      "[10,  1000] loss: 0.922\n",
      "[11,  1000] loss: 0.819\n",
      "[12,  1000] loss: 0.743\n",
      "[13,  1000] loss: 0.633\n",
      "[14,  1000] loss: 0.586\n",
      "[15,  1000] loss: 0.483\n",
      "[16,  1000] loss: 0.406\n",
      "[17,  1000] loss: 0.349\n",
      "[18,  1000] loss: 0.291\n",
      "[19,  1000] loss: 0.277\n",
      "[20,  1000] loss: 0.210\n",
      "[21,  1000] loss: 0.213\n",
      "[22,  1000] loss: 0.156\n",
      "[23,  1000] loss: 0.167\n",
      "[24,  1000] loss: 0.127\n",
      "[25,  1000] loss: 0.119\n",
      "[26,  1000] loss: 0.131\n",
      "[27,  1000] loss: 0.229\n",
      "[28,  1000] loss: 0.109\n",
      "[29,  1000] loss: 0.148\n",
      "[30,  1000] loss: 0.065\n",
      "Time: 93\n",
      "Accuracy of the network on the 80000 test images: 46 %\n",
      "Conv out channels:  10\n",
      "[1,  1000] loss: 2.109\n",
      "[2,  1000] loss: 1.719\n",
      "[3,  1000] loss: 1.526\n",
      "[4,  1000] loss: 1.412\n",
      "[5,  1000] loss: 1.302\n",
      "[6,  1000] loss: 1.198\n",
      "[7,  1000] loss: 1.127\n",
      "[8,  1000] loss: 0.997\n",
      "[9,  1000] loss: 0.915\n",
      "[10,  1000] loss: 0.791\n",
      "[11,  1000] loss: 0.694\n",
      "[12,  1000] loss: 0.600\n",
      "[13,  1000] loss: 0.491\n",
      "[14,  1000] loss: 0.393\n",
      "[15,  1000] loss: 0.333\n",
      "[16,  1000] loss: 0.264\n",
      "[17,  1000] loss: 0.238\n",
      "[18,  1000] loss: 0.159\n",
      "[19,  1000] loss: 0.187\n",
      "[20,  1000] loss: 0.104\n",
      "[21,  1000] loss: 0.124\n",
      "[22,  1000] loss: 0.160\n",
      "[23,  1000] loss: 0.186\n",
      "[24,  1000] loss: 0.059\n",
      "[25,  1000] loss: 0.074\n",
      "[26,  1000] loss: 0.039\n",
      "[27,  1000] loss: 0.071\n",
      "[28,  1000] loss: 0.021\n",
      "[29,  1000] loss: 0.007\n",
      "[30,  1000] loss: 0.002\n",
      "Time: 124\n",
      "Accuracy of the network on the 80000 test images: 49 %\n",
      "Conv out channels:  15\n",
      "[1,  1000] loss: 2.069\n",
      "[2,  1000] loss: 1.664\n",
      "[3,  1000] loss: 1.524\n",
      "[4,  1000] loss: 1.394\n",
      "[5,  1000] loss: 1.273\n",
      "[6,  1000] loss: 1.167\n",
      "[7,  1000] loss: 1.046\n",
      "[8,  1000] loss: 0.943\n",
      "[9,  1000] loss: 0.809\n",
      "[10,  1000] loss: 0.710\n",
      "[11,  1000] loss: 0.582\n",
      "[12,  1000] loss: 0.483\n",
      "[13,  1000] loss: 0.383\n",
      "[14,  1000] loss: 0.304\n",
      "[15,  1000] loss: 0.262\n",
      "[16,  1000] loss: 0.230\n",
      "[17,  1000] loss: 0.137\n",
      "[18,  1000] loss: 0.119\n",
      "[19,  1000] loss: 0.096\n",
      "[20,  1000] loss: 0.137\n",
      "[21,  1000] loss: 0.097\n",
      "[22,  1000] loss: 0.080\n",
      "[23,  1000] loss: 0.034\n",
      "[24,  1000] loss: 0.046\n",
      "[25,  1000] loss: 0.022\n",
      "[26,  1000] loss: 0.017\n",
      "[27,  1000] loss: 0.003\n",
      "[28,  1000] loss: 0.002\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 163\n",
      "Accuracy of the network on the 80000 test images: 51 %\n",
      "Conv out channels:  20\n",
      "[1,  1000] loss: 2.040\n",
      "[2,  1000] loss: 1.637\n",
      "[3,  1000] loss: 1.442\n",
      "[4,  1000] loss: 1.321\n",
      "[5,  1000] loss: 1.200\n",
      "[6,  1000] loss: 1.094\n",
      "[7,  1000] loss: 0.991\n",
      "[8,  1000] loss: 0.881\n",
      "[9,  1000] loss: 0.755\n",
      "[10,  1000] loss: 0.600\n",
      "[11,  1000] loss: 0.506\n",
      "[12,  1000] loss: 0.370\n",
      "[13,  1000] loss: 0.329\n",
      "[14,  1000] loss: 0.239\n",
      "[15,  1000] loss: 0.168\n",
      "[16,  1000] loss: 0.210\n",
      "[17,  1000] loss: 0.094\n",
      "[18,  1000] loss: 0.084\n",
      "[19,  1000] loss: 0.063\n",
      "[20,  1000] loss: 0.133\n",
      "[21,  1000] loss: 0.153\n",
      "[22,  1000] loss: 0.055\n",
      "[23,  1000] loss: 0.039\n",
      "[24,  1000] loss: 0.038\n",
      "[25,  1000] loss: 0.039\n",
      "[26,  1000] loss: 0.011\n",
      "[27,  1000] loss: 0.004\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 187\n",
      "Accuracy of the network on the 80000 test images: 54 %\n",
      "Conv out channels:  25\n",
      "[1,  1000] loss: 1.989\n",
      "[2,  1000] loss: 1.623\n",
      "[3,  1000] loss: 1.427\n",
      "[4,  1000] loss: 1.317\n",
      "[5,  1000] loss: 1.192\n",
      "[6,  1000] loss: 1.072\n",
      "[7,  1000] loss: 0.965\n",
      "[8,  1000] loss: 0.821\n",
      "[9,  1000] loss: 0.700\n",
      "[10,  1000] loss: 0.551\n",
      "[11,  1000] loss: 0.433\n",
      "[12,  1000] loss: 0.351\n",
      "[13,  1000] loss: 0.239\n",
      "[14,  1000] loss: 0.226\n",
      "[15,  1000] loss: 0.142\n",
      "[16,  1000] loss: 0.168\n",
      "[17,  1000] loss: 0.082\n",
      "[18,  1000] loss: 0.073\n",
      "[19,  1000] loss: 0.066\n",
      "[20,  1000] loss: 0.062\n",
      "[21,  1000] loss: 0.059\n",
      "[22,  1000] loss: 0.052\n",
      "[23,  1000] loss: 0.058\n",
      "[24,  1000] loss: 0.055\n",
      "[25,  1000] loss: 0.036\n",
      "[26,  1000] loss: 0.062\n",
      "[27,  1000] loss: 0.044\n",
      "[28,  1000] loss: 0.008\n",
      "[29,  1000] loss: 0.012\n",
      "[30,  1000] loss: 0.002\n",
      "Time: 218\n",
      "Accuracy of the network on the 80000 test images: 52 %\n",
      "Conv out channels:  30\n",
      "[1,  1000] loss: 2.028\n",
      "[2,  1000] loss: 1.632\n",
      "[3,  1000] loss: 1.458\n",
      "[4,  1000] loss: 1.324\n",
      "[5,  1000] loss: 1.196\n",
      "[6,  1000] loss: 1.085\n",
      "[7,  1000] loss: 0.971\n",
      "[8,  1000] loss: 0.839\n",
      "[9,  1000] loss: 0.719\n",
      "[10,  1000] loss: 0.583\n",
      "[11,  1000] loss: 0.460\n",
      "[12,  1000] loss: 0.355\n",
      "[13,  1000] loss: 0.277\n",
      "[14,  1000] loss: 0.193\n",
      "[15,  1000] loss: 0.128\n",
      "[16,  1000] loss: 0.118\n",
      "[17,  1000] loss: 0.082\n",
      "[18,  1000] loss: 0.037\n",
      "[19,  1000] loss: 0.007\n",
      "[20,  1000] loss: 0.003\n",
      "[21,  1000] loss: 0.002\n",
      "[22,  1000] loss: 0.002\n",
      "[23,  1000] loss: 0.001\n",
      "[24,  1000] loss: 0.001\n",
      "[25,  1000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 260\n",
      "Accuracy of the network on the 80000 test images: 55 %\n",
      "Conv out channels:  35\n",
      "[1,  1000] loss: 1.980\n",
      "[2,  1000] loss: 1.613\n",
      "[3,  1000] loss: 1.417\n",
      "[4,  1000] loss: 1.288\n",
      "[5,  1000] loss: 1.169\n",
      "[6,  1000] loss: 1.062\n",
      "[7,  1000] loss: 0.917\n",
      "[8,  1000] loss: 0.796\n",
      "[9,  1000] loss: 0.679\n",
      "[10,  1000] loss: 0.507\n",
      "[11,  1000] loss: 0.383\n",
      "[12,  1000] loss: 0.273\n",
      "[13,  1000] loss: 0.209\n",
      "[14,  1000] loss: 0.152\n",
      "[15,  1000] loss: 0.123\n",
      "[16,  1000] loss: 0.095\n",
      "[17,  1000] loss: 0.141\n",
      "[18,  1000] loss: 0.085\n",
      "[19,  1000] loss: 0.089\n",
      "[20,  1000] loss: 0.023\n",
      "[21,  1000] loss: 0.007\n",
      "[22,  1000] loss: 0.002\n",
      "[23,  1000] loss: 0.002\n",
      "[24,  1000] loss: 0.001\n",
      "[25,  1000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 312\n",
      "Accuracy of the network on the 80000 test images: 54 %\n",
      "Conv out channels:  40\n",
      "[1,  1000] loss: 2.030\n",
      "[2,  1000] loss: 1.617\n",
      "[3,  1000] loss: 1.430\n",
      "[4,  1000] loss: 1.274\n",
      "[5,  1000] loss: 1.158\n",
      "[6,  1000] loss: 1.027\n",
      "[7,  1000] loss: 0.901\n",
      "[8,  1000] loss: 0.787\n",
      "[9,  1000] loss: 0.639\n",
      "[10,  1000] loss: 0.499\n",
      "[11,  1000] loss: 0.345\n",
      "[12,  1000] loss: 0.247\n",
      "[13,  1000] loss: 0.196\n",
      "[14,  1000] loss: 0.166\n",
      "[15,  1000] loss: 0.098\n",
      "[16,  1000] loss: 0.098\n",
      "[17,  1000] loss: 0.088\n",
      "[18,  1000] loss: 0.111\n",
      "[19,  1000] loss: 0.026\n",
      "[20,  1000] loss: 0.037\n",
      "[21,  1000] loss: 0.006\n",
      "[22,  1000] loss: 0.003\n",
      "[23,  1000] loss: 0.001\n",
      "[24,  1000] loss: 0.001\n",
      "[25,  1000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n",
      "Time: 329\n",
      "Accuracy of the network on the 80000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "losses_channels = []\n",
    "\n",
    "for conv1_out_channels in range(5, 45, 5):\n",
    "    loss_tmp = []\n",
    "    print('Conv out channels: ', conv1_out_channels)\n",
    "    net = ConvNet(conv1_kernel_size=4, \\\n",
    "                      conv1_out_channels=conv1_out_channels, \\\n",
    "                      layers_num=1)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(30):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 1000 == 999:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                loss_tmp.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "    losses_channels.append(loss_tmp)\n",
    "    print('Time: %d' % (timeit.default_timer() - start_time))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "    print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eac7e048>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAzk8Kz/1FPSsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ead2c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(30), losses_channels[0])\n",
    "plt.plot(range(30), losses_channels[1])\n",
    "plt.plot(range(30), losses_channels[2])\n",
    "plt.plot(range(30), losses_channels[3])\n",
    "plt.plot(range(30), losses_channels[4])\n",
    "plt.plot(range(30), losses_channels[5], 'o--')\n",
    "plt.plot(range(30), losses_channels[6])\n",
    "plt.plot(range(30), losses_channels[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что лучшее качество 55 % на тестовой выборке достигается у модели с 30 фильтрами на сверточном слое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем проверить, улучшит ли качество добавление еще одного сверточного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers:  2\n"
     ]
    }
   ],
   "source": [
    "print('Number of layers: ', 2)\n",
    "net = ConvNet(conv1_kernel_size=6, \\\n",
    "                  conv1_out_channels=40, \\\n",
    "                  layers_num=2)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 0.128\n",
      "[2,  1000] loss: 0.043\n",
      "[3,  1000] loss: 0.029\n",
      "[4,  1000] loss: 0.022\n",
      "[5,  1000] loss: 0.019\n",
      "[6,  1000] loss: 0.016\n",
      "[7,  1000] loss: 0.014\n",
      "[8,  1000] loss: 0.014\n",
      "[9,  1000] loss: 0.012\n",
      "[10,  1000] loss: 0.011\n",
      "[11,  1000] loss: 0.011\n",
      "[12,  1000] loss: 0.009\n",
      "[13,  1000] loss: 0.009\n",
      "[14,  1000] loss: 0.008\n",
      "[15,  1000] loss: 0.008\n",
      "[16,  1000] loss: 0.007\n",
      "[17,  1000] loss: 0.007\n",
      "[18,  1000] loss: 0.006\n",
      "[19,  1000] loss: 0.006\n",
      "[20,  1000] loss: 0.006\n",
      "[21,  1000] loss: 0.005\n",
      "[22,  1000] loss: 0.006\n",
      "[23,  1000] loss: 0.005\n",
      "[24,  1000] loss: 0.005\n",
      "[25,  1000] loss: 0.005\n",
      "[26,  1000] loss: 0.005\n",
      "[27,  1000] loss: 0.005\n",
      "[28,  1000] loss: 0.004\n",
      "[29,  1000] loss: 0.004\n",
      "[30,  1000] loss: 0.004\n",
      "[31,  1000] loss: 0.004\n",
      "[32,  1000] loss: 0.004\n",
      "[33,  1000] loss: 0.004\n",
      "[34,  1000] loss: 0.004\n",
      "[35,  1000] loss: 0.003\n",
      "[36,  1000] loss: 0.003\n",
      "[37,  1000] loss: 0.003\n",
      "[38,  1000] loss: 0.003\n",
      "[39,  1000] loss: 0.003\n",
      "[40,  1000] loss: 0.003\n",
      "[41,  1000] loss: 0.003\n",
      "[42,  1000] loss: 0.003\n",
      "[43,  1000] loss: 0.003\n",
      "[44,  1000] loss: 0.003\n",
      "[45,  1000] loss: 0.003\n",
      "[46,  1000] loss: 0.003\n",
      "[47,  1000] loss: 0.003\n",
      "[48,  1000] loss: 0.003\n",
      "[49,  1000] loss: 0.003\n",
      "[50,  1000] loss: 0.003\n",
      "Time:  200.2162650130049\n",
      "Accuracy of the network on the 80000 test images: 41 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двухслойная сеть была обучена за 150 эпох и качество не превысило  41 %. Поэтому в дальнейшем использовалась однослойная сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем значение momentum для метода SGD. До этого использовалось значение momentum = 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=6, \\\n",
    "                  conv1_out_channels=40, \\\n",
    "                  layers_num=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.983\n",
      "[2,  1000] loss: 1.598\n",
      "[3,  1000] loss: 1.441\n",
      "[4,  1000] loss: 1.319\n",
      "[5,  1000] loss: 1.180\n",
      "[6,  1000] loss: 1.081\n",
      "[7,  1000] loss: 0.965\n",
      "[8,  1000] loss: 0.835\n",
      "[9,  1000] loss: 0.695\n",
      "[10,  1000] loss: 0.606\n",
      "[11,  1000] loss: 0.495\n",
      "[12,  1000] loss: 0.360\n",
      "[13,  1000] loss: 0.267\n",
      "[14,  1000] loss: 0.222\n",
      "[15,  1000] loss: 0.152\n",
      "[16,  1000] loss: 0.168\n",
      "[17,  1000] loss: 0.136\n",
      "[18,  1000] loss: 0.188\n",
      "[19,  1000] loss: 0.122\n",
      "[20,  1000] loss: 0.080\n",
      "[21,  1000] loss: 0.118\n",
      "[22,  1000] loss: 0.119\n",
      "[23,  1000] loss: 0.082\n",
      "[24,  1000] loss: 0.040\n",
      "[25,  1000] loss: 0.040\n",
      "[26,  1000] loss: 0.086\n",
      "[27,  1000] loss: 0.030\n",
      "[28,  1000] loss: 0.004\n",
      "[29,  1000] loss: 0.002\n",
      "[30,  1000] loss: 0.001\n",
      "[31,  1000] loss: 0.001\n",
      "[32,  1000] loss: 0.001\n",
      "[33,  1000] loss: 0.001\n",
      "[34,  1000] loss: 0.001\n",
      "[35,  1000] loss: 0.001\n",
      "[36,  1000] loss: 0.001\n",
      "[37,  1000] loss: 0.001\n",
      "[38,  1000] loss: 0.000\n",
      "[39,  1000] loss: 0.000\n",
      "[40,  1000] loss: 0.000\n",
      "[41,  1000] loss: 0.000\n",
      "[42,  1000] loss: 0.000\n",
      "[43,  1000] loss: 0.000\n",
      "[44,  1000] loss: 0.000\n",
      "[45,  1000] loss: 0.000\n",
      "[46,  1000] loss: 0.000\n",
      "[47,  1000] loss: 0.000\n",
      "[48,  1000] loss: 0.000\n",
      "[49,  1000] loss: 0.000\n",
      "[50,  1000] loss: 0.000\n",
      "Time:  463.9299777740089\n",
      "Accuracy of the network on the 80000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=6, \\\n",
    "                  conv1_out_channels=40, \\\n",
    "                  layers_num=1)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.287\n",
      "[2,  1000] loss: 2.180\n",
      "[3,  1000] loss: 1.982\n",
      "[4,  1000] loss: 1.849\n",
      "[5,  1000] loss: 1.757\n",
      "[6,  1000] loss: 1.691\n",
      "[7,  1000] loss: 1.633\n",
      "[8,  1000] loss: 1.573\n",
      "[9,  1000] loss: 1.539\n",
      "[10,  1000] loss: 1.497\n",
      "[11,  1000] loss: 1.441\n",
      "[12,  1000] loss: 1.405\n",
      "[13,  1000] loss: 1.370\n",
      "[14,  1000] loss: 1.329\n",
      "[15,  1000] loss: 1.287\n",
      "[16,  1000] loss: 1.259\n",
      "[17,  1000] loss: 1.221\n",
      "[18,  1000] loss: 1.181\n",
      "[19,  1000] loss: 1.146\n",
      "[20,  1000] loss: 1.121\n",
      "[21,  1000] loss: 1.082\n",
      "[22,  1000] loss: 1.061\n",
      "[23,  1000] loss: 1.026\n",
      "[24,  1000] loss: 0.985\n",
      "[25,  1000] loss: 0.943\n",
      "[26,  1000] loss: 0.916\n",
      "[27,  1000] loss: 0.883\n",
      "[28,  1000] loss: 0.850\n",
      "[29,  1000] loss: 0.816\n",
      "[30,  1000] loss: 0.771\n",
      "[31,  1000] loss: 0.735\n",
      "[32,  1000] loss: 0.704\n",
      "[33,  1000] loss: 0.669\n",
      "[34,  1000] loss: 0.623\n",
      "[35,  1000] loss: 0.581\n",
      "[36,  1000] loss: 0.539\n",
      "[37,  1000] loss: 0.497\n",
      "[38,  1000] loss: 0.476\n",
      "[39,  1000] loss: 0.414\n",
      "[40,  1000] loss: 0.402\n",
      "[41,  1000] loss: 0.360\n",
      "[42,  1000] loss: 0.314\n",
      "[43,  1000] loss: 0.290\n",
      "[44,  1000] loss: 0.254\n",
      "[45,  1000] loss: 0.221\n",
      "[46,  1000] loss: 0.195\n",
      "[47,  1000] loss: 0.177\n",
      "[48,  1000] loss: 0.145\n",
      "[49,  1000] loss: 0.128\n",
      "[50,  1000] loss: 0.114\n",
      "Time:  458.0666976089997\n",
      "Accuracy of the network on the 80000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=6, \\\n",
    "                  conv1_out_channels=40, \\\n",
    "                  layers_num=1)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.017\n",
      "[2,  1000] loss: 1.613\n",
      "[3,  1000] loss: 1.444\n",
      "[4,  1000] loss: 1.337\n",
      "[5,  1000] loss: 1.214\n",
      "[6,  1000] loss: 1.080\n",
      "[7,  1000] loss: 0.962\n",
      "[8,  1000] loss: 0.867\n",
      "[9,  1000] loss: 0.731\n",
      "[10,  1000] loss: 0.570\n",
      "[11,  1000] loss: 0.453\n",
      "[12,  1000] loss: 0.378\n",
      "[13,  1000] loss: 0.326\n",
      "[14,  1000] loss: 0.221\n",
      "[15,  1000] loss: 0.196\n",
      "[16,  1000] loss: 0.144\n",
      "[17,  1000] loss: 0.123\n",
      "[18,  1000] loss: 0.106\n",
      "[19,  1000] loss: 0.082\n",
      "[20,  1000] loss: 0.129\n",
      "[21,  1000] loss: 0.118\n",
      "[22,  1000] loss: 0.084\n",
      "[23,  1000] loss: 0.083\n",
      "[24,  1000] loss: 0.026\n",
      "[25,  1000] loss: 0.033\n",
      "[26,  1000] loss: 0.065\n",
      "[27,  1000] loss: 0.051\n",
      "[28,  1000] loss: 0.048\n",
      "[29,  1000] loss: 0.020\n",
      "[30,  1000] loss: 0.005\n",
      "[31,  1000] loss: 0.003\n",
      "[32,  1000] loss: 0.003\n",
      "[33,  1000] loss: 0.003\n",
      "[34,  1000] loss: 0.003\n",
      "[35,  1000] loss: 0.002\n",
      "[36,  1000] loss: 0.002\n",
      "[37,  1000] loss: 0.002\n",
      "[38,  1000] loss: 0.002\n",
      "[39,  1000] loss: 0.002\n",
      "[40,  1000] loss: 0.002\n",
      "Time:  372.5535196510027\n",
      "Accuracy of the network on the 80000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(40):\n",
    "    running_loss = 0.0\n",
    "    if epoch == 28:\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.0, weight_decay=1e-4)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(опционально) использования специальных методов оптимизации для нейросетей (Adam, Adagrad . . . )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=2, \\\n",
    "                  conv1_out_channels=30, \\\n",
    "                  layers_num=1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.861\n",
      "[2,  1000] loss: 1.509\n",
      "[3,  1000] loss: 1.321\n",
      "[4,  1000] loss: 1.193\n",
      "[5,  1000] loss: 1.062\n",
      "[6,  1000] loss: 0.952\n",
      "[7,  1000] loss: 0.834\n",
      "[8,  1000] loss: 0.722\n",
      "[9,  1000] loss: 0.624\n",
      "[10,  1000] loss: 0.546\n",
      "[11,  1000] loss: 0.469\n",
      "[12,  1000] loss: 0.413\n",
      "[13,  1000] loss: 0.363\n",
      "[14,  1000] loss: 0.248\n",
      "[15,  1000] loss: 0.293\n",
      "[16,  1000] loss: 0.222\n",
      "[17,  1000] loss: 0.199\n",
      "[18,  1000] loss: 0.203\n",
      "[19,  1000] loss: 0.215\n",
      "[20,  1000] loss: 0.144\n",
      "[21,  1000] loss: 0.138\n",
      "[22,  1000] loss: 0.167\n",
      "[23,  1000] loss: 0.133\n",
      "[24,  1000] loss: 0.147\n",
      "[25,  1000] loss: 0.100\n",
      "[26,  1000] loss: 0.145\n",
      "[27,  1000] loss: 0.119\n",
      "[28,  1000] loss: 0.117\n",
      "[29,  1000] loss: 0.108\n",
      "[30,  1000] loss: 0.110\n",
      "Time:  1793.1189016990102\n",
      "Accuracy of the network on the 80000 test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=2, \\\n",
    "                  conv1_out_channels=30, \\\n",
    "                  layers_num=1)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.955\n",
      "[2,  1000] loss: 1.760\n",
      "[3,  1000] loss: 1.705\n",
      "[4,  1000] loss: 1.647\n",
      "[5,  1000] loss: 1.617\n",
      "[6,  1000] loss: 1.592\n",
      "[7,  1000] loss: 1.555\n",
      "[8,  1000] loss: 1.542\n",
      "[9,  1000] loss: 1.522\n",
      "[10,  1000] loss: 1.500\n",
      "[11,  1000] loss: 1.483\n",
      "[12,  1000] loss: 1.476\n",
      "[13,  1000] loss: 1.463\n",
      "[14,  1000] loss: 1.452\n",
      "[15,  1000] loss: 1.434\n",
      "[16,  1000] loss: 1.426\n",
      "[17,  1000] loss: 1.421\n",
      "[18,  1000] loss: 1.401\n",
      "[19,  1000] loss: 1.393\n",
      "[20,  1000] loss: 1.376\n",
      "[21,  1000] loss: 1.373\n",
      "[22,  1000] loss: 1.366\n",
      "[23,  1000] loss: 1.359\n",
      "[24,  1000] loss: 1.348\n",
      "[25,  1000] loss: 1.336\n",
      "[26,  1000] loss: 1.336\n",
      "[27,  1000] loss: 1.325\n",
      "[28,  1000] loss: 1.326\n",
      "[29,  1000] loss: 1.313\n",
      "[30,  1000] loss: 1.309\n",
      "Time:  866.1395086999983\n",
      "Accuracy of the network on the 80000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "print('Time: ', timeit.default_timer() - start_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "                100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=4, \\\n",
    "                      conv1_out_channels=30, \\\n",
    "                      layers_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images: 53 %\n",
      "Log-loss of the network on the 8000 test images:  0.9153981669416044\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    loss = criterion(outputs, Variable(labels))\n",
    "    running_loss += loss.data[0]\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 8000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Log-loss of the network on the 8000 test images: ',\n",
    "    running_loss / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Автоэнкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 30, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (30, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = ConvAutoEncoder(conv_out_channels=30)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 5, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (5, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.164\n",
      "[1,  4000] loss: 0.092\n",
      "[1,  6000] loss: 0.072\n",
      "[1,  8000] loss: 0.069\n",
      "[1, 10000] loss: 0.067\n",
      "[1, 12000] loss: 0.066\n",
      "[1, 14000] loss: 0.065\n",
      "[1, 16000] loss: 0.063\n",
      "[1, 18000] loss: 0.061\n",
      "[1, 20000] loss: 0.059\n",
      "[1, 22000] loss: 0.058\n",
      "[1, 24000] loss: 0.057\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.055\n",
      "[2,  4000] loss: 0.054\n",
      "[2,  6000] loss: 0.054\n",
      "[2,  8000] loss: 0.053\n",
      "[2, 10000] loss: 0.052\n",
      "[2, 12000] loss: 0.052\n",
      "[2, 14000] loss: 0.052\n",
      "[2, 16000] loss: 0.051\n",
      "[2, 18000] loss: 0.051\n",
      "[2, 20000] loss: 0.051\n",
      "[2, 22000] loss: 0.050\n",
      "[2, 24000] loss: 0.050\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.049\n",
      "[3,  4000] loss: 0.050\n",
      "[3,  6000] loss: 0.050\n",
      "[3,  8000] loss: 0.050\n",
      "[3, 10000] loss: 0.049\n",
      "[3, 12000] loss: 0.050\n",
      "[3, 14000] loss: 0.049\n",
      "[3, 16000] loss: 0.049\n",
      "[3, 18000] loss: 0.049\n",
      "[3, 20000] loss: 0.049\n",
      "[3, 22000] loss: 0.049\n",
      "[3, 24000] loss: 0.049\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.049\n",
      "[4,  4000] loss: 0.049\n",
      "[4,  6000] loss: 0.048\n",
      "[4,  8000] loss: 0.048\n",
      "[4, 10000] loss: 0.048\n",
      "[4, 12000] loss: 0.049\n",
      "[4, 14000] loss: 0.049\n",
      "[4, 16000] loss: 0.049\n",
      "[4, 18000] loss: 0.049\n",
      "[4, 20000] loss: 0.049\n",
      "[4, 22000] loss: 0.048\n",
      "[4, 24000] loss: 0.049\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.048\n",
      "[5,  4000] loss: 0.048\n",
      "[5,  6000] loss: 0.048\n",
      "[5,  8000] loss: 0.048\n",
      "[5, 10000] loss: 0.048\n",
      "[5, 12000] loss: 0.048\n",
      "[5, 14000] loss: 0.048\n",
      "[5, 16000] loss: 0.048\n",
      "[5, 18000] loss: 0.049\n",
      "[5, 20000] loss: 0.048\n",
      "[5, 22000] loss: 0.048\n",
      "[5, 24000] loss: 0.048\n",
      "Test loss =  0.012211314221844077\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 10, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (10, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.120\n",
      "[1,  4000] loss: 0.069\n",
      "[1,  6000] loss: 0.065\n",
      "[1,  8000] loss: 0.062\n",
      "[1, 10000] loss: 0.060\n",
      "[1, 12000] loss: 0.057\n",
      "[1, 14000] loss: 0.056\n",
      "[1, 16000] loss: 0.055\n",
      "[1, 18000] loss: 0.053\n",
      "[1, 20000] loss: 0.051\n",
      "[1, 22000] loss: 0.049\n",
      "[1, 24000] loss: 0.047\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.045\n",
      "[2,  4000] loss: 0.044\n",
      "[2,  6000] loss: 0.043\n",
      "[2,  8000] loss: 0.042\n",
      "[2, 10000] loss: 0.042\n",
      "[2, 12000] loss: 0.041\n",
      "[2, 14000] loss: 0.040\n",
      "[2, 16000] loss: 0.039\n",
      "[2, 18000] loss: 0.039\n",
      "[2, 20000] loss: 0.038\n",
      "[2, 22000] loss: 0.038\n",
      "[2, 24000] loss: 0.037\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.036\n",
      "[3,  4000] loss: 0.036\n",
      "[3,  6000] loss: 0.036\n",
      "[3,  8000] loss: 0.035\n",
      "[3, 10000] loss: 0.034\n",
      "[3, 12000] loss: 0.034\n",
      "[3, 14000] loss: 0.034\n",
      "[3, 16000] loss: 0.033\n",
      "[3, 18000] loss: 0.033\n",
      "[3, 20000] loss: 0.033\n",
      "[3, 22000] loss: 0.032\n",
      "[3, 24000] loss: 0.032\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.032\n",
      "[4,  4000] loss: 0.032\n",
      "[4,  6000] loss: 0.031\n",
      "[4,  8000] loss: 0.031\n",
      "[4, 10000] loss: 0.031\n",
      "[4, 12000] loss: 0.031\n",
      "[4, 14000] loss: 0.030\n",
      "[4, 16000] loss: 0.031\n",
      "[4, 18000] loss: 0.030\n",
      "[4, 20000] loss: 0.030\n",
      "[4, 22000] loss: 0.030\n",
      "[4, 24000] loss: 0.029\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.029\n",
      "[5,  4000] loss: 0.030\n",
      "[5,  6000] loss: 0.029\n",
      "[5,  8000] loss: 0.029\n",
      "[5, 10000] loss: 0.029\n",
      "[5, 12000] loss: 0.029\n",
      "[5, 14000] loss: 0.029\n",
      "[5, 16000] loss: 0.029\n",
      "[5, 18000] loss: 0.028\n",
      "[5, 20000] loss: 0.028\n",
      "[5, 22000] loss: 0.028\n",
      "[5, 24000] loss: 0.028\n",
      "Test loss =  0.007104627907648682\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 15, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (15, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.119\n",
      "[1,  4000] loss: 0.066\n",
      "[1,  6000] loss: 0.062\n",
      "[1,  8000] loss: 0.059\n",
      "[1, 10000] loss: 0.055\n",
      "[1, 12000] loss: 0.052\n",
      "[1, 14000] loss: 0.049\n",
      "[1, 16000] loss: 0.047\n",
      "[1, 18000] loss: 0.044\n",
      "[1, 20000] loss: 0.042\n",
      "[1, 22000] loss: 0.040\n",
      "[1, 24000] loss: 0.039\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.037\n",
      "[2,  4000] loss: 0.035\n",
      "[2,  6000] loss: 0.034\n",
      "[2,  8000] loss: 0.033\n",
      "[2, 10000] loss: 0.032\n",
      "[2, 12000] loss: 0.032\n",
      "[2, 14000] loss: 0.031\n",
      "[2, 16000] loss: 0.031\n",
      "[2, 18000] loss: 0.030\n",
      "[2, 20000] loss: 0.029\n",
      "[2, 22000] loss: 0.029\n",
      "[2, 24000] loss: 0.029\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.028\n",
      "[3,  4000] loss: 0.028\n",
      "[3,  6000] loss: 0.028\n",
      "[3,  8000] loss: 0.027\n",
      "[3, 10000] loss: 0.027\n",
      "[3, 12000] loss: 0.027\n",
      "[3, 14000] loss: 0.027\n",
      "[3, 16000] loss: 0.026\n",
      "[3, 18000] loss: 0.026\n",
      "[3, 20000] loss: 0.026\n",
      "[3, 22000] loss: 0.026\n",
      "[3, 24000] loss: 0.026\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.026\n",
      "[4,  4000] loss: 0.025\n",
      "[4,  6000] loss: 0.025\n",
      "[4,  8000] loss: 0.025\n",
      "[4, 10000] loss: 0.025\n",
      "[4, 12000] loss: 0.025\n",
      "[4, 14000] loss: 0.025\n",
      "[4, 16000] loss: 0.025\n",
      "[4, 18000] loss: 0.025\n",
      "[4, 20000] loss: 0.025\n",
      "[4, 22000] loss: 0.024\n",
      "[4, 24000] loss: 0.025\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.025\n",
      "[5,  4000] loss: 0.024\n",
      "[5,  6000] loss: 0.024\n",
      "[5,  8000] loss: 0.024\n",
      "[5, 10000] loss: 0.024\n",
      "[5, 12000] loss: 0.024\n",
      "[5, 14000] loss: 0.024\n",
      "[5, 16000] loss: 0.024\n",
      "[5, 18000] loss: 0.024\n",
      "[5, 20000] loss: 0.024\n",
      "[5, 22000] loss: 0.024\n",
      "[5, 24000] loss: 0.024\n",
      "Test loss =  0.0060089033884927635\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 20, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (20, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.099\n",
      "[1,  4000] loss: 0.058\n",
      "[1,  6000] loss: 0.053\n",
      "[1,  8000] loss: 0.049\n",
      "[1, 10000] loss: 0.046\n",
      "[1, 12000] loss: 0.043\n",
      "[1, 14000] loss: 0.041\n",
      "[1, 16000] loss: 0.038\n",
      "[1, 18000] loss: 0.037\n",
      "[1, 20000] loss: 0.036\n",
      "[1, 22000] loss: 0.035\n",
      "[1, 24000] loss: 0.033\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.032\n",
      "[2,  4000] loss: 0.031\n",
      "[2,  6000] loss: 0.030\n",
      "[2,  8000] loss: 0.030\n",
      "[2, 10000] loss: 0.029\n",
      "[2, 12000] loss: 0.028\n",
      "[2, 14000] loss: 0.028\n",
      "[2, 16000] loss: 0.028\n",
      "[2, 18000] loss: 0.027\n",
      "[2, 20000] loss: 0.026\n",
      "[2, 22000] loss: 0.026\n",
      "[2, 24000] loss: 0.026\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.026\n",
      "[3,  4000] loss: 0.025\n",
      "[3,  6000] loss: 0.025\n",
      "[3,  8000] loss: 0.024\n",
      "[3, 10000] loss: 0.024\n",
      "[3, 12000] loss: 0.024\n",
      "[3, 14000] loss: 0.024\n",
      "[3, 16000] loss: 0.024\n",
      "[3, 18000] loss: 0.023\n",
      "[3, 20000] loss: 0.023\n",
      "[3, 22000] loss: 0.023\n",
      "[3, 24000] loss: 0.023\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.023\n",
      "[4,  4000] loss: 0.023\n",
      "[4,  6000] loss: 0.022\n",
      "[4,  8000] loss: 0.022\n",
      "[4, 10000] loss: 0.022\n",
      "[4, 12000] loss: 0.022\n",
      "[4, 14000] loss: 0.022\n",
      "[4, 16000] loss: 0.022\n",
      "[4, 18000] loss: 0.022\n",
      "[4, 20000] loss: 0.022\n",
      "[4, 22000] loss: 0.022\n",
      "[4, 24000] loss: 0.022\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.021\n",
      "[5,  4000] loss: 0.021\n",
      "[5,  6000] loss: 0.021\n",
      "[5,  8000] loss: 0.021\n",
      "[5, 10000] loss: 0.021\n",
      "[5, 12000] loss: 0.021\n",
      "[5, 14000] loss: 0.021\n",
      "[5, 16000] loss: 0.021\n",
      "[5, 18000] loss: 0.021\n",
      "[5, 20000] loss: 0.021\n",
      "[5, 22000] loss: 0.021\n",
      "[5, 24000] loss: 0.021\n",
      "Test loss =  0.00531795676574111\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 25, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (25, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.107\n",
      "[1,  4000] loss: 0.061\n",
      "[1,  6000] loss: 0.055\n",
      "[1,  8000] loss: 0.051\n",
      "[1, 10000] loss: 0.047\n",
      "[1, 12000] loss: 0.044\n",
      "[1, 14000] loss: 0.041\n",
      "[1, 16000] loss: 0.039\n",
      "[1, 18000] loss: 0.037\n",
      "[1, 20000] loss: 0.035\n",
      "[1, 22000] loss: 0.034\n",
      "[1, 24000] loss: 0.032\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.031\n",
      "[2,  4000] loss: 0.030\n",
      "[2,  6000] loss: 0.029\n",
      "[2,  8000] loss: 0.028\n",
      "[2, 10000] loss: 0.027\n",
      "[2, 12000] loss: 0.027\n",
      "[2, 14000] loss: 0.026\n",
      "[2, 16000] loss: 0.026\n",
      "[2, 18000] loss: 0.025\n",
      "[2, 20000] loss: 0.025\n",
      "[2, 22000] loss: 0.025\n",
      "[2, 24000] loss: 0.024\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.024\n",
      "[3,  4000] loss: 0.023\n",
      "[3,  6000] loss: 0.023\n",
      "[3,  8000] loss: 0.023\n",
      "[3, 10000] loss: 0.022\n",
      "[3, 12000] loss: 0.022\n",
      "[3, 14000] loss: 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 16000] loss: 0.022\n",
      "[3, 18000] loss: 0.022\n",
      "[3, 20000] loss: 0.021\n",
      "[3, 22000] loss: 0.021\n",
      "[3, 24000] loss: 0.021\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.021\n",
      "[4,  4000] loss: 0.021\n",
      "[4,  6000] loss: 0.021\n",
      "[4,  8000] loss: 0.021\n",
      "[4, 10000] loss: 0.020\n",
      "[4, 12000] loss: 0.020\n",
      "[4, 14000] loss: 0.020\n",
      "[4, 16000] loss: 0.020\n",
      "[4, 18000] loss: 0.020\n",
      "[4, 20000] loss: 0.020\n",
      "[4, 22000] loss: 0.020\n",
      "[4, 24000] loss: 0.020\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.020\n",
      "[5,  4000] loss: 0.020\n",
      "[5,  6000] loss: 0.020\n",
      "[5,  8000] loss: 0.019\n",
      "[5, 10000] loss: 0.020\n",
      "[5, 12000] loss: 0.019\n",
      "[5, 14000] loss: 0.019\n",
      "[5, 16000] loss: 0.019\n",
      "[5, 18000] loss: 0.019\n",
      "[5, 20000] loss: 0.019\n",
      "[5, 22000] loss: 0.019\n",
      "[5, 24000] loss: 0.019\n",
      "Test loss =  0.00486219621244818\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 30, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (30, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.101\n",
      "[1,  4000] loss: 0.058\n",
      "[1,  6000] loss: 0.053\n",
      "[1,  8000] loss: 0.048\n",
      "[1, 10000] loss: 0.045\n",
      "[1, 12000] loss: 0.042\n",
      "[1, 14000] loss: 0.040\n",
      "[1, 16000] loss: 0.037\n",
      "[1, 18000] loss: 0.036\n",
      "[1, 20000] loss: 0.034\n",
      "[1, 22000] loss: 0.033\n",
      "[1, 24000] loss: 0.032\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.030\n",
      "[2,  4000] loss: 0.030\n",
      "[2,  6000] loss: 0.029\n",
      "[2,  8000] loss: 0.028\n",
      "[2, 10000] loss: 0.027\n",
      "[2, 12000] loss: 0.027\n",
      "[2, 14000] loss: 0.026\n",
      "[2, 16000] loss: 0.025\n",
      "[2, 18000] loss: 0.025\n",
      "[2, 20000] loss: 0.025\n",
      "[2, 22000] loss: 0.024\n",
      "[2, 24000] loss: 0.024\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.023\n",
      "[3,  4000] loss: 0.023\n",
      "[3,  6000] loss: 0.022\n",
      "[3,  8000] loss: 0.022\n",
      "[3, 10000] loss: 0.022\n",
      "[3, 12000] loss: 0.022\n",
      "[3, 14000] loss: 0.022\n",
      "[3, 16000] loss: 0.021\n",
      "[3, 18000] loss: 0.021\n",
      "[3, 20000] loss: 0.021\n",
      "[3, 22000] loss: 0.021\n",
      "[3, 24000] loss: 0.021\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.020\n",
      "[4,  4000] loss: 0.020\n",
      "[4,  6000] loss: 0.020\n",
      "[4,  8000] loss: 0.020\n",
      "[4, 10000] loss: 0.020\n",
      "[4, 12000] loss: 0.020\n",
      "[4, 14000] loss: 0.020\n",
      "[4, 16000] loss: 0.020\n",
      "[4, 18000] loss: 0.020\n",
      "[4, 20000] loss: 0.019\n",
      "[4, 22000] loss: 0.019\n",
      "[4, 24000] loss: 0.019\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.019\n",
      "[5,  4000] loss: 0.019\n",
      "[5,  6000] loss: 0.019\n",
      "[5,  8000] loss: 0.019\n",
      "[5, 10000] loss: 0.019\n",
      "[5, 12000] loss: 0.019\n",
      "[5, 14000] loss: 0.019\n",
      "[5, 16000] loss: 0.019\n",
      "[5, 18000] loss: 0.019\n",
      "[5, 20000] loss: 0.019\n",
      "[5, 22000] loss: 0.019\n",
      "[5, 24000] loss: 0.019\n",
      "Test loss =  0.004738639912940562\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 35, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (35, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.103\n",
      "[1,  4000] loss: 0.056\n",
      "[1,  6000] loss: 0.050\n",
      "[1,  8000] loss: 0.044\n",
      "[1, 10000] loss: 0.040\n",
      "[1, 12000] loss: 0.038\n",
      "[1, 14000] loss: 0.035\n",
      "[1, 16000] loss: 0.034\n",
      "[1, 18000] loss: 0.032\n",
      "[1, 20000] loss: 0.031\n",
      "[1, 22000] loss: 0.030\n",
      "[1, 24000] loss: 0.029\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.028\n",
      "[2,  4000] loss: 0.027\n",
      "[2,  6000] loss: 0.026\n",
      "[2,  8000] loss: 0.026\n",
      "[2, 10000] loss: 0.025\n",
      "[2, 12000] loss: 0.025\n",
      "[2, 14000] loss: 0.024\n",
      "[2, 16000] loss: 0.024\n",
      "[2, 18000] loss: 0.024\n",
      "[2, 20000] loss: 0.023\n",
      "[2, 22000] loss: 0.023\n",
      "[2, 24000] loss: 0.022\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.022\n",
      "[3,  4000] loss: 0.022\n",
      "[3,  6000] loss: 0.021\n",
      "[3,  8000] loss: 0.021\n",
      "[3, 10000] loss: 0.021\n",
      "[3, 12000] loss: 0.021\n",
      "[3, 14000] loss: 0.021\n",
      "[3, 16000] loss: 0.020\n",
      "[3, 18000] loss: 0.020\n",
      "[3, 20000] loss: 0.020\n",
      "[3, 22000] loss: 0.020\n",
      "[3, 24000] loss: 0.020\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.020\n",
      "[4,  4000] loss: 0.020\n",
      "[4,  6000] loss: 0.019\n",
      "[4,  8000] loss: 0.019\n",
      "[4, 10000] loss: 0.019\n",
      "[4, 12000] loss: 0.019\n",
      "[4, 14000] loss: 0.019\n",
      "[4, 16000] loss: 0.019\n",
      "[4, 18000] loss: 0.019\n",
      "[4, 20000] loss: 0.019\n",
      "[4, 22000] loss: 0.019\n",
      "[4, 24000] loss: 0.019\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.019\n",
      "[5,  4000] loss: 0.018\n",
      "[5,  6000] loss: 0.018\n",
      "[5,  8000] loss: 0.018\n",
      "[5, 10000] loss: 0.018\n",
      "[5, 12000] loss: 0.018\n",
      "[5, 14000] loss: 0.018\n",
      "[5, 16000] loss: 0.018\n",
      "[5, 18000] loss: 0.018\n",
      "[5, 20000] loss: 0.018\n",
      "[5, 22000] loss: 0.018\n",
      "[5, 24000] loss: 0.018\n",
      "Test loss =  0.004558907137066126\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.094\n",
      "[1,  4000] loss: 0.054\n",
      "[1,  6000] loss: 0.048\n",
      "[1,  8000] loss: 0.043\n",
      "[1, 10000] loss: 0.039\n",
      "[1, 12000] loss: 0.036\n",
      "[1, 14000] loss: 0.035\n",
      "[1, 16000] loss: 0.033\n",
      "[1, 18000] loss: 0.031\n",
      "[1, 20000] loss: 0.030\n",
      "[1, 22000] loss: 0.029\n",
      "[1, 24000] loss: 0.028\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.027\n",
      "[2,  4000] loss: 0.026\n",
      "[2,  6000] loss: 0.026\n",
      "[2,  8000] loss: 0.025\n",
      "[2, 10000] loss: 0.024\n",
      "[2, 12000] loss: 0.023\n",
      "[2, 14000] loss: 0.023\n",
      "[2, 16000] loss: 0.023\n",
      "[2, 18000] loss: 0.022\n",
      "[2, 20000] loss: 0.022\n",
      "[2, 22000] loss: 0.022\n",
      "[2, 24000] loss: 0.021\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.021\n",
      "[3,  4000] loss: 0.021\n",
      "[3,  6000] loss: 0.020\n",
      "[3,  8000] loss: 0.020\n",
      "[3, 10000] loss: 0.020\n",
      "[3, 12000] loss: 0.020\n",
      "[3, 14000] loss: 0.019\n",
      "[3, 16000] loss: 0.019\n",
      "[3, 18000] loss: 0.019\n",
      "[3, 20000] loss: 0.019\n",
      "[3, 22000] loss: 0.019\n",
      "[3, 24000] loss: 0.019\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.019\n",
      "[4,  4000] loss: 0.018\n",
      "[4,  6000] loss: 0.018\n",
      "[4,  8000] loss: 0.018\n",
      "[4, 10000] loss: 0.018\n",
      "[4, 12000] loss: 0.018\n",
      "[4, 14000] loss: 0.018\n",
      "[4, 16000] loss: 0.018\n",
      "[4, 18000] loss: 0.018\n",
      "[4, 20000] loss: 0.018\n",
      "[4, 22000] loss: 0.017\n",
      "[4, 24000] loss: 0.017\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.018\n",
      "[5,  4000] loss: 0.017\n",
      "[5,  6000] loss: 0.017\n",
      "[5,  8000] loss: 0.017\n",
      "[5, 10000] loss: 0.017\n",
      "[5, 12000] loss: 0.017\n",
      "[5, 14000] loss: 0.017\n",
      "[5, 16000] loss: 0.017\n",
      "[5, 18000] loss: 0.017\n",
      "[5, 20000] loss: 0.017\n",
      "[5, 22000] loss: 0.017\n",
      "[5, 24000] loss: 0.017\n",
      "Test loss =  0.004338272070325911\n"
     ]
    }
   ],
   "source": [
    "for conv_out_channels in range(5, 45, 5):\n",
    "    autoencoder = ConvAutoEncoder(conv_out_channels=conv_out_channels)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "    print(autoencoder)\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        print(\"Epoch %d\" % epoch)\n",
    "\n",
    "        for i, (images,_) in enumerate(unlabeledloader):    # Ignore image labels\n",
    "            optimizer.zero_grad()\n",
    "            out, code = autoencoder(Variable(images))\n",
    "\n",
    "            loss = criterion(out, Variable(images))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    total = 0.0\n",
    "    counter = 0\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        counter += 4\n",
    "        outputs, _ = autoencoder(Variable(images))\n",
    "        total += criterion(outputs, Variable(images)).data[0]\n",
    "    print('Test loss = ', total / counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "видно что при значениях числа фильтров на сверточном слое от 25 до 40 итоговый MSE на отложенной выборке не сильно меняется "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем добиться улучшения засчет настройки padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.118\n",
      "[1,  4000] loss: 0.074\n",
      "[1,  6000] loss: 0.068\n",
      "[1,  8000] loss: 0.064\n",
      "[1, 10000] loss: 0.059\n",
      "[1, 12000] loss: 0.055\n",
      "[1, 14000] loss: 0.052\n",
      "[1, 16000] loss: 0.050\n",
      "[1, 18000] loss: 0.048\n",
      "[1, 20000] loss: 0.047\n",
      "[1, 22000] loss: 0.045\n",
      "[1, 24000] loss: 0.044\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.043\n",
      "[2,  4000] loss: 0.043\n",
      "[2,  6000] loss: 0.041\n",
      "[2,  8000] loss: 0.040\n",
      "[2, 10000] loss: 0.040\n",
      "[2, 12000] loss: 0.039\n",
      "[2, 14000] loss: 0.039\n",
      "[2, 16000] loss: 0.038\n",
      "[2, 18000] loss: 0.037\n",
      "[2, 20000] loss: 0.037\n",
      "[2, 22000] loss: 0.037\n",
      "[2, 24000] loss: 0.037\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.036\n",
      "[3,  4000] loss: 0.035\n",
      "[3,  6000] loss: 0.035\n",
      "[3,  8000] loss: 0.035\n",
      "[3, 10000] loss: 0.035\n",
      "[3, 12000] loss: 0.034\n",
      "[3, 14000] loss: 0.034\n",
      "[3, 16000] loss: 0.034\n",
      "[3, 18000] loss: 0.033\n",
      "[3, 20000] loss: 0.033\n",
      "[3, 22000] loss: 0.033\n",
      "[3, 24000] loss: 0.033\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.033\n",
      "[4,  4000] loss: 0.032\n",
      "[4,  6000] loss: 0.032\n",
      "[4,  8000] loss: 0.032\n",
      "[4, 10000] loss: 0.032\n",
      "[4, 12000] loss: 0.032\n",
      "[4, 14000] loss: 0.032\n",
      "[4, 16000] loss: 0.032\n",
      "[4, 18000] loss: 0.031\n",
      "[4, 20000] loss: 0.032\n",
      "[4, 22000] loss: 0.032\n",
      "[4, 24000] loss: 0.031\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.031\n",
      "[5,  4000] loss: 0.031\n",
      "[5,  6000] loss: 0.031\n",
      "[5,  8000] loss: 0.031\n",
      "[5, 10000] loss: 0.031\n",
      "[5, 12000] loss: 0.031\n",
      "[5, 14000] loss: 0.031\n",
      "[5, 16000] loss: 0.031\n",
      "[5, 18000] loss: 0.031\n",
      "[5, 20000] loss: 0.031\n",
      "[5, 22000] loss: 0.031\n",
      "[5, 24000] loss: 0.030\n",
      "Test loss =  0.0074038407469168305\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.081\n",
      "[1,  4000] loss: 0.044\n",
      "[1,  6000] loss: 0.036\n",
      "[1,  8000] loss: 0.030\n",
      "[1, 10000] loss: 0.028\n",
      "[1, 12000] loss: 0.025\n",
      "[1, 14000] loss: 0.024\n",
      "[1, 16000] loss: 0.022\n",
      "[1, 18000] loss: 0.021\n",
      "[1, 20000] loss: 0.020\n",
      "[1, 22000] loss: 0.019\n",
      "[1, 24000] loss: 0.018\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.018\n",
      "[2,  4000] loss: 0.017\n",
      "[2,  6000] loss: 0.016\n",
      "[2,  8000] loss: 0.016\n",
      "[2, 10000] loss: 0.016\n",
      "[2, 12000] loss: 0.015\n",
      "[2, 14000] loss: 0.015\n",
      "[2, 16000] loss: 0.015\n",
      "[2, 18000] loss: 0.014\n",
      "[2, 20000] loss: 0.014\n",
      "[2, 22000] loss: 0.014\n",
      "[2, 24000] loss: 0.014\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.014\n",
      "[3,  4000] loss: 0.014\n",
      "[3,  6000] loss: 0.013\n",
      "[3,  8000] loss: 0.013\n",
      "[3, 10000] loss: 0.013\n",
      "[3, 12000] loss: 0.013\n",
      "[3, 14000] loss: 0.013\n",
      "[3, 16000] loss: 0.013\n",
      "[3, 18000] loss: 0.012\n",
      "[3, 20000] loss: 0.012\n",
      "[3, 22000] loss: 0.012\n",
      "[3, 24000] loss: 0.012\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.012\n",
      "[4,  4000] loss: 0.012\n",
      "[4,  6000] loss: 0.012\n",
      "[4,  8000] loss: 0.011\n",
      "[4, 10000] loss: 0.012\n",
      "[4, 12000] loss: 0.011\n",
      "[4, 14000] loss: 0.011\n",
      "[4, 16000] loss: 0.011\n",
      "[4, 18000] loss: 0.011\n",
      "[4, 20000] loss: 0.011\n",
      "[4, 22000] loss: 0.011\n",
      "[4, 24000] loss: 0.011\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.011\n",
      "[5,  4000] loss: 0.011\n",
      "[5,  6000] loss: 0.011\n",
      "[5,  8000] loss: 0.011\n",
      "[5, 10000] loss: 0.011\n",
      "[5, 12000] loss: 0.010\n",
      "[5, 14000] loss: 0.010\n",
      "[5, 16000] loss: 0.010\n",
      "[5, 18000] loss: 0.010\n",
      "[5, 20000] loss: 0.010\n",
      "[5, 22000] loss: 0.010\n",
      "[5, 24000] loss: 0.010\n",
      "Test loss =  0.002497305136825889\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.067\n",
      "[1,  4000] loss: 0.034\n",
      "[1,  6000] loss: 0.027\n",
      "[1,  8000] loss: 0.024\n",
      "[1, 10000] loss: 0.021\n",
      "[1, 12000] loss: 0.019\n",
      "[1, 14000] loss: 0.019\n",
      "[1, 16000] loss: 0.018\n",
      "[1, 18000] loss: 0.017\n",
      "[1, 20000] loss: 0.016\n",
      "[1, 22000] loss: 0.016\n",
      "[1, 24000] loss: 0.015\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.015\n",
      "[2,  4000] loss: 0.014\n",
      "[2,  6000] loss: 0.014\n",
      "[2,  8000] loss: 0.014\n",
      "[2, 10000] loss: 0.014\n",
      "[2, 12000] loss: 0.013\n",
      "[2, 14000] loss: 0.013\n",
      "[2, 16000] loss: 0.013\n",
      "[2, 18000] loss: 0.012\n",
      "[2, 20000] loss: 0.012\n",
      "[2, 22000] loss: 0.012\n",
      "[2, 24000] loss: 0.012\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.012\n",
      "[3,  4000] loss: 0.012\n",
      "[3,  6000] loss: 0.012\n",
      "[3,  8000] loss: 0.011\n",
      "[3, 10000] loss: 0.011\n",
      "[3, 12000] loss: 0.011\n",
      "[3, 14000] loss: 0.011\n",
      "[3, 16000] loss: 0.011\n",
      "[3, 18000] loss: 0.011\n",
      "[3, 20000] loss: 0.011\n",
      "[3, 22000] loss: 0.011\n",
      "[3, 24000] loss: 0.011\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.011\n",
      "[4,  4000] loss: 0.010\n",
      "[4,  6000] loss: 0.010\n",
      "[4,  8000] loss: 0.010\n",
      "[4, 10000] loss: 0.010\n",
      "[4, 12000] loss: 0.010\n",
      "[4, 14000] loss: 0.010\n",
      "[4, 16000] loss: 0.010\n",
      "[4, 18000] loss: 0.010\n",
      "[4, 20000] loss: 0.010\n",
      "[4, 22000] loss: 0.010\n",
      "[4, 24000] loss: 0.010\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.010\n",
      "[5,  4000] loss: 0.010\n",
      "[5,  6000] loss: 0.010\n",
      "[5,  8000] loss: 0.010\n",
      "[5, 10000] loss: 0.009\n",
      "[5, 12000] loss: 0.009\n",
      "[5, 14000] loss: 0.009\n",
      "[5, 16000] loss: 0.009\n",
      "[5, 18000] loss: 0.009\n",
      "[5, 20000] loss: 0.009\n",
      "[5, 22000] loss: 0.009\n",
      "[5, 24000] loss: 0.009\n",
      "Test loss =  0.002235241798125207\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.067\n",
      "[1,  4000] loss: 0.033\n",
      "[1,  6000] loss: 0.027\n",
      "[1,  8000] loss: 0.023\n",
      "[1, 10000] loss: 0.021\n",
      "[1, 12000] loss: 0.020\n",
      "[1, 14000] loss: 0.019\n",
      "[1, 16000] loss: 0.018\n",
      "[1, 18000] loss: 0.017\n",
      "[1, 20000] loss: 0.017\n",
      "[1, 22000] loss: 0.016\n",
      "[1, 24000] loss: 0.016\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.015\n",
      "[2,  4000] loss: 0.015\n",
      "[2,  6000] loss: 0.014\n",
      "[2,  8000] loss: 0.014\n",
      "[2, 10000] loss: 0.014\n",
      "[2, 12000] loss: 0.014\n",
      "[2, 14000] loss: 0.013\n",
      "[2, 16000] loss: 0.013\n",
      "[2, 18000] loss: 0.013\n",
      "[2, 20000] loss: 0.013\n",
      "[2, 22000] loss: 0.013\n",
      "[2, 24000] loss: 0.012\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.012\n",
      "[3,  4000] loss: 0.012\n",
      "[3,  6000] loss: 0.012\n",
      "[3,  8000] loss: 0.012\n",
      "[3, 10000] loss: 0.012\n",
      "[3, 12000] loss: 0.011\n",
      "[3, 14000] loss: 0.011\n",
      "[3, 16000] loss: 0.011\n",
      "[3, 18000] loss: 0.011\n",
      "[3, 20000] loss: 0.011\n",
      "[3, 22000] loss: 0.011\n",
      "[3, 24000] loss: 0.011\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.011\n",
      "[4,  4000] loss: 0.011\n",
      "[4,  6000] loss: 0.010\n",
      "[4,  8000] loss: 0.010\n",
      "[4, 10000] loss: 0.010\n",
      "[4, 12000] loss: 0.010\n",
      "[4, 14000] loss: 0.010\n",
      "[4, 16000] loss: 0.010\n",
      "[4, 18000] loss: 0.010\n",
      "[4, 20000] loss: 0.010\n",
      "[4, 22000] loss: 0.010\n",
      "[4, 24000] loss: 0.010\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.010\n",
      "[5,  4000] loss: 0.010\n",
      "[5,  6000] loss: 0.010\n",
      "[5,  8000] loss: 0.010\n",
      "[5, 10000] loss: 0.010\n",
      "[5, 12000] loss: 0.010\n",
      "[5, 14000] loss: 0.009\n",
      "[5, 16000] loss: 0.009\n",
      "[5, 18000] loss: 0.009\n",
      "[5, 20000] loss: 0.009\n",
      "[5, 22000] loss: 0.009\n",
      "[5, 24000] loss: 0.009\n",
      "Test loss =  0.0022306096095591785\n",
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(10, 10), stride=(2, 2), padding=(4, 4))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(10, 10), stride=(2, 2), padding=(4, 4))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n",
      "Epoch 0\n",
      "[1,  2000] loss: 0.063\n",
      "[1,  4000] loss: 0.032\n",
      "[1,  6000] loss: 0.026\n",
      "[1,  8000] loss: 0.023\n",
      "[1, 10000] loss: 0.021\n",
      "[1, 12000] loss: 0.020\n",
      "[1, 14000] loss: 0.019\n",
      "[1, 16000] loss: 0.018\n",
      "[1, 18000] loss: 0.018\n",
      "[1, 20000] loss: 0.017\n",
      "[1, 22000] loss: 0.016\n",
      "[1, 24000] loss: 0.016\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.015\n",
      "[2,  4000] loss: 0.015\n",
      "[2,  6000] loss: 0.015\n",
      "[2,  8000] loss: 0.015\n",
      "[2, 10000] loss: 0.014\n",
      "[2, 12000] loss: 0.014\n",
      "[2, 14000] loss: 0.014\n",
      "[2, 16000] loss: 0.013\n",
      "[2, 18000] loss: 0.013\n",
      "[2, 20000] loss: 0.013\n",
      "[2, 22000] loss: 0.013\n",
      "[2, 24000] loss: 0.013\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.013\n",
      "[3,  4000] loss: 0.012\n",
      "[3,  6000] loss: 0.012\n",
      "[3,  8000] loss: 0.012\n",
      "[3, 10000] loss: 0.012\n",
      "[3, 12000] loss: 0.012\n",
      "[3, 14000] loss: 0.012\n",
      "[3, 16000] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 18000] loss: 0.012\n",
      "[3, 20000] loss: 0.011\n",
      "[3, 22000] loss: 0.011\n",
      "[3, 24000] loss: 0.011\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.011\n",
      "[4,  4000] loss: 0.011\n",
      "[4,  6000] loss: 0.011\n",
      "[4,  8000] loss: 0.011\n",
      "[4, 10000] loss: 0.011\n",
      "[4, 12000] loss: 0.011\n",
      "[4, 14000] loss: 0.011\n",
      "[4, 16000] loss: 0.011\n",
      "[4, 18000] loss: 0.010\n",
      "[4, 20000] loss: 0.010\n",
      "[4, 22000] loss: 0.010\n",
      "[4, 24000] loss: 0.010\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.010\n",
      "[5,  4000] loss: 0.010\n",
      "[5,  6000] loss: 0.010\n",
      "[5,  8000] loss: 0.010\n",
      "[5, 10000] loss: 0.010\n",
      "[5, 12000] loss: 0.010\n",
      "[5, 14000] loss: 0.010\n",
      "[5, 16000] loss: 0.010\n",
      "[5, 18000] loss: 0.010\n",
      "[5, 20000] loss: 0.010\n",
      "[5, 22000] loss: 0.010\n",
      "[5, 24000] loss: 0.010\n",
      "Test loss =  0.0023080769794527442\n"
     ]
    }
   ],
   "source": [
    "for padding in range(5):\n",
    "    autoencoder = ConvAutoEncoder(conv_out_channels=40, conv_padding=padding, conv_kernel_size=2 * (padding + 1))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "    print(autoencoder)\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        print(\"Epoch %d\" % epoch)\n",
    "\n",
    "        for i, (images,_) in enumerate(unlabeledloader):    # Ignore image labels\n",
    "            optimizer.zero_grad()\n",
    "            out, code = autoencoder(Variable(images))\n",
    "\n",
    "            loss = criterion(out, Variable(images))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    total = 0.0\n",
    "    counter = 0\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        counter += 4\n",
    "        outputs, _ = autoencoder(Variable(images))\n",
    "        total += criterion(outputs, Variable(images)).data[0]\n",
    "    print('Test loss = ', total / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 40, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
      "  (transpose): ConvTranspose2d (40, 3, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = ConvAutoEncoder(conv_out_channels=40, conv_padding=3, conv_kernel_size=2 * (3 + 1))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[1,  2000] loss: 0.065\n",
      "[1,  4000] loss: 0.033\n",
      "[1,  6000] loss: 0.027\n",
      "[1,  8000] loss: 0.023\n",
      "[1, 10000] loss: 0.021\n",
      "[1, 12000] loss: 0.020\n",
      "[1, 14000] loss: 0.019\n",
      "[1, 16000] loss: 0.018\n",
      "[1, 18000] loss: 0.017\n",
      "[1, 20000] loss: 0.016\n",
      "[1, 22000] loss: 0.016\n",
      "[1, 24000] loss: 0.015\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.015\n",
      "[2,  4000] loss: 0.014\n",
      "[2,  6000] loss: 0.014\n",
      "[2,  8000] loss: 0.014\n",
      "[2, 10000] loss: 0.014\n",
      "[2, 12000] loss: 0.013\n",
      "[2, 14000] loss: 0.013\n",
      "[2, 16000] loss: 0.013\n",
      "[2, 18000] loss: 0.013\n",
      "[2, 20000] loss: 0.013\n",
      "[2, 22000] loss: 0.012\n",
      "[2, 24000] loss: 0.012\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.012\n",
      "[3,  4000] loss: 0.012\n",
      "[3,  6000] loss: 0.012\n",
      "[3,  8000] loss: 0.012\n",
      "[3, 10000] loss: 0.012\n",
      "[3, 12000] loss: 0.011\n",
      "[3, 14000] loss: 0.011\n",
      "[3, 16000] loss: 0.011\n",
      "[3, 18000] loss: 0.011\n",
      "[3, 20000] loss: 0.011\n",
      "[3, 22000] loss: 0.011\n",
      "[3, 24000] loss: 0.011\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.011\n",
      "[4,  4000] loss: 0.011\n",
      "[4,  6000] loss: 0.011\n",
      "[4,  8000] loss: 0.010\n",
      "[4, 10000] loss: 0.010\n",
      "[4, 12000] loss: 0.010\n",
      "[4, 14000] loss: 0.010\n",
      "[4, 16000] loss: 0.010\n",
      "[4, 18000] loss: 0.010\n",
      "[4, 20000] loss: 0.010\n",
      "[4, 22000] loss: 0.010\n",
      "[4, 24000] loss: 0.010\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.010\n",
      "[5,  4000] loss: 0.010\n",
      "[5,  6000] loss: 0.010\n",
      "[5,  8000] loss: 0.010\n",
      "[5, 10000] loss: 0.010\n",
      "[5, 12000] loss: 0.010\n",
      "[5, 14000] loss: 0.010\n",
      "[5, 16000] loss: 0.010\n",
      "[5, 18000] loss: 0.010\n",
      "[5, 20000] loss: 0.009\n",
      "[5, 22000] loss: 0.009\n",
      "[5, 24000] loss: 0.009\n",
      "Epoch 5\n",
      "[6,  2000] loss: 0.009\n",
      "[6,  4000] loss: 0.009\n",
      "[6,  6000] loss: 0.009\n",
      "[6,  8000] loss: 0.009\n",
      "[6, 10000] loss: 0.009\n",
      "[6, 12000] loss: 0.009\n",
      "[6, 14000] loss: 0.009\n",
      "[6, 16000] loss: 0.009\n",
      "[6, 18000] loss: 0.009\n",
      "[6, 20000] loss: 0.009\n",
      "[6, 22000] loss: 0.009\n",
      "[6, 24000] loss: 0.009\n",
      "Epoch 6\n",
      "[7,  2000] loss: 0.009\n",
      "[7,  4000] loss: 0.009\n",
      "[7,  6000] loss: 0.009\n",
      "[7,  8000] loss: 0.009\n",
      "[7, 10000] loss: 0.009\n",
      "[7, 12000] loss: 0.009\n",
      "[7, 14000] loss: 0.009\n",
      "[7, 16000] loss: 0.009\n",
      "[7, 18000] loss: 0.009\n",
      "[7, 20000] loss: 0.009\n",
      "[7, 22000] loss: 0.009\n",
      "[7, 24000] loss: 0.009\n",
      "Epoch 7\n",
      "[8,  2000] loss: 0.009\n",
      "[8,  4000] loss: 0.009\n",
      "[8,  6000] loss: 0.009\n",
      "[8,  8000] loss: 0.008\n",
      "[8, 10000] loss: 0.009\n",
      "[8, 12000] loss: 0.009\n",
      "[8, 14000] loss: 0.008\n",
      "[8, 16000] loss: 0.008\n",
      "[8, 18000] loss: 0.008\n",
      "[8, 20000] loss: 0.008\n",
      "[8, 22000] loss: 0.008\n",
      "[8, 24000] loss: 0.008\n",
      "Epoch 8\n",
      "[9,  2000] loss: 0.008\n",
      "[9,  4000] loss: 0.008\n",
      "[9,  6000] loss: 0.008\n",
      "[9,  8000] loss: 0.008\n",
      "[9, 10000] loss: 0.008\n",
      "[9, 12000] loss: 0.008\n",
      "[9, 14000] loss: 0.008\n",
      "[9, 16000] loss: 0.008\n",
      "[9, 18000] loss: 0.008\n",
      "[9, 20000] loss: 0.008\n",
      "[9, 22000] loss: 0.008\n",
      "[9, 24000] loss: 0.008\n",
      "Epoch 9\n",
      "[10,  2000] loss: 0.008\n",
      "[10,  4000] loss: 0.008\n",
      "[10,  6000] loss: 0.008\n",
      "[10,  8000] loss: 0.008\n",
      "[10, 10000] loss: 0.008\n",
      "[10, 12000] loss: 0.008\n",
      "[10, 14000] loss: 0.008\n",
      "[10, 16000] loss: 0.008\n",
      "[10, 18000] loss: 0.008\n",
      "[10, 20000] loss: 0.008\n",
      "[10, 22000] loss: 0.008\n",
      "[10, 24000] loss: 0.008\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "\n",
    "    for i, (images,_) in enumerate(unlabeledloader):    # Ignore image labels\n",
    "        optimizer.zero_grad()\n",
    "        out, code = autoencoder(Variable(images))\n",
    "\n",
    "        loss = criterion(out, Variable(images))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  0.0019220161563251168\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "counter = 0\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    counter += 4\n",
    "    outputs, _ = autoencoder(Variable(images))\n",
    "    total += criterion(outputs, Variable(images)).data[0]\n",
    "print('Test loss = ', total / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5b6f0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(unlabeledloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(autoencoder(Variable(images))[0].data))\n",
    "plt.savefig('new2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKccKIkr9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eac75358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.savefig('old2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Используем признаки из автоэнкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Multinomial(nn.Module):\n",
    "    def __init__(self, input_size=3 * 32 * 32):\n",
    "        super(Multinomial, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mult = Multinomial(input_size=9000)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mult.parameters(), momentum=0.9, lr=0.001, weight_decay=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(mult.parameters(), momentum=0.0, lr=0.001, weight_decay=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.954\n",
      "[2,  1000] loss: 1.633\n",
      "[3,  1000] loss: 1.508\n",
      "[4,  1000] loss: 1.411\n",
      "[5,  1000] loss: 1.353\n",
      "[6,  1000] loss: 1.300\n",
      "[7,  1000] loss: 1.242\n",
      "[8,  1000] loss: 1.195\n",
      "[9,  1000] loss: 1.151\n",
      "[10,  1000] loss: 1.111\n",
      "[11,  1000] loss: 1.089\n",
      "[12,  1000] loss: 1.050\n",
      "[13,  1000] loss: 1.023\n",
      "[14,  1000] loss: 0.993\n",
      "[15,  1000] loss: 0.967\n",
      "[16,  1000] loss: 0.946\n",
      "[17,  1000] loss: 0.932\n",
      "[18,  1000] loss: 0.900\n",
      "[19,  1000] loss: 0.885\n",
      "[20,  1000] loss: 0.856\n",
      "[21,  1000] loss: 0.845\n",
      "[22,  1000] loss: 0.830\n",
      "[23,  1000] loss: 0.814\n",
      "[24,  1000] loss: 0.792\n",
      "[25,  1000] loss: 0.784\n",
      "[26,  1000] loss: 0.770\n",
      "[27,  1000] loss: 0.754\n",
      "[28,  1000] loss: 0.752\n",
      "[29,  1000] loss: 0.735\n",
      "[30,  1000] loss: 0.711\n",
      "[31,  1000] loss: 0.695\n",
      "[32,  1000] loss: 0.692\n",
      "[33,  1000] loss: 0.680\n",
      "[34,  1000] loss: 0.668\n",
      "[35,  1000] loss: 0.651\n",
      "[36,  1000] loss: 0.648\n",
      "[37,  1000] loss: 0.637\n",
      "[38,  1000] loss: 0.622\n",
      "[39,  1000] loss: 0.609\n",
      "[40,  1000] loss: 0.603\n",
      "[41,  1000] loss: 0.600\n",
      "[42,  1000] loss: 0.585\n",
      "[43,  1000] loss: 0.588\n",
      "[44,  1000] loss: 0.573\n",
      "[45,  1000] loss: 0.560\n",
      "[46,  1000] loss: 0.554\n",
      "[47,  1000] loss: 0.551\n",
      "[48,  1000] loss: 0.534\n",
      "[49,  1000] loss: 0.524\n",
      "[50,  1000] loss: 0.524\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        images, labels = data\n",
    "        _, code = autoencoder.forward(x=Variable(images))\n",
    "        tmp = code.data.view(4, -1)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(tmp), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mult(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images: 51 %\n",
      "Log-loss of the network on the 8000 test images:  0.37072302227746695\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    _, code = autoencoder.forward(x=Variable(images))\n",
    "    tmp = code.data.view(4, -1)\n",
    "        \n",
    "    outputs = mult(Variable(tmp))\n",
    "    \n",
    "    loss = criterion(outputs, Variable(labels))\n",
    "    running_loss += loss.data[0]\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 8000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Log-loss of the network on the 8000 test images: ',\n",
    "    running_loss / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что засчет использования признаков, выделенных автокодировщиком, качество работы мультиномиальной регрессии улучшилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    X_tmp, y_tmp = data\n",
    "    for elem in y_tmp:\n",
    "        y_train.append(elem)\n",
    " \n",
    "    _, code = autoencoder.forward(x=Variable(X_tmp))\n",
    "    \n",
    "    tmp = np.array(code.data.view(4, -1))\n",
    "    if type(X_train) is list:\n",
    "        X_train = tmp\n",
    "    else:\n",
    "        X_train = np.vstack((X_train, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images: 36 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "for data in testloader:\n",
    "    X_test, y_test = data\n",
    "    \n",
    "    _, code = autoencoder.forward(x=Variable(X_test))\n",
    "    \n",
    "    tmp = np.array(code.data.view(4, -1))\n",
    "    \n",
    "    outputs = clf.predict(tmp)\n",
    "    total += y_test.size(0)\n",
    "    correct += (outputs == y_test).sum()\n",
    "\n",
    "\n",
    "print('Accuracy of the network on the 8000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество работы алгоритма RandomForest не изменилось. Это объясняется тем, что"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Используем признаки из автоэнкодера для инициализации сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conv' from '/Users/Galya/Documents/studying/6th_semester/prac/task_1/conv.py'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = conv.ConvNet(conv1_kernel_size=8, \\\n",
    "                   conv1_padding=0, \\\n",
    "                         weight=autoencoder.conv.weight, \\\n",
    "                      conv1_out_channels=40, \\\n",
    "                      layers_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.747\n",
      "[2,  1000] loss: 1.374\n",
      "[3,  1000] loss: 1.184\n",
      "[4,  1000] loss: 1.056\n",
      "[5,  1000] loss: 0.900\n",
      "[6,  1000] loss: 0.748\n",
      "[7,  1000] loss: 0.625\n",
      "[8,  1000] loss: 0.510\n",
      "[9,  1000] loss: 0.427\n",
      "[10,  1000] loss: 0.305\n",
      "[11,  1000] loss: 0.239\n",
      "[12,  1000] loss: 0.150\n",
      "[13,  1000] loss: 0.163\n",
      "[14,  1000] loss: 0.197\n",
      "[15,  1000] loss: 0.150\n",
      "[16,  1000] loss: 0.174\n",
      "[17,  1000] loss: 0.133\n",
      "[18,  1000] loss: 0.116\n",
      "[19,  1000] loss: 0.059\n",
      "[20,  1000] loss: 0.043\n",
      "[21,  1000] loss: 0.063\n",
      "[22,  1000] loss: 0.008\n",
      "[23,  1000] loss: 0.002\n",
      "[24,  1000] loss: 0.001\n",
      "[25,  1000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "    \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 0.001\n",
      "[2,  1000] loss: 0.001\n",
      "[3,  1000] loss: 0.000\n",
      "[4,  1000] loss: 0.000\n",
      "[5,  1000] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "    \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 80000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "            100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Не сильно улучшилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 30, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (transpose): ConvTranspose2d (30, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder_for_net = ConvAutoEncoder(conv_out_channels=30, conv_padding=1, conv_kernel_size=2 * (1 + 1))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(autoencoder_for_net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "print(autoencoder_for_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[1,  2000] loss: 0.082\n",
      "[1,  4000] loss: 0.051\n",
      "[1,  6000] loss: 0.039\n",
      "[1,  8000] loss: 0.033\n",
      "[1, 10000] loss: 0.029\n",
      "[1, 12000] loss: 0.027\n",
      "[1, 14000] loss: 0.025\n",
      "[1, 16000] loss: 0.024\n",
      "[1, 18000] loss: 0.022\n",
      "[1, 20000] loss: 0.021\n",
      "[1, 22000] loss: 0.020\n",
      "[1, 24000] loss: 0.020\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.019\n",
      "[2,  4000] loss: 0.018\n",
      "[2,  6000] loss: 0.018\n",
      "[2,  8000] loss: 0.017\n",
      "[2, 10000] loss: 0.017\n",
      "[2, 12000] loss: 0.017\n",
      "[2, 14000] loss: 0.016\n",
      "[2, 16000] loss: 0.016\n",
      "[2, 18000] loss: 0.016\n",
      "[2, 20000] loss: 0.015\n",
      "[2, 22000] loss: 0.015\n",
      "[2, 24000] loss: 0.015\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.015\n",
      "[3,  4000] loss: 0.015\n",
      "[3,  6000] loss: 0.014\n",
      "[3,  8000] loss: 0.014\n",
      "[3, 10000] loss: 0.014\n",
      "[3, 12000] loss: 0.014\n",
      "[3, 14000] loss: 0.014\n",
      "[3, 16000] loss: 0.014\n",
      "[3, 18000] loss: 0.014\n",
      "[3, 20000] loss: 0.013\n",
      "[3, 22000] loss: 0.013\n",
      "[3, 24000] loss: 0.013\n",
      "Epoch 3\n",
      "[4,  2000] loss: 0.013\n",
      "[4,  4000] loss: 0.013\n",
      "[4,  6000] loss: 0.013\n",
      "[4,  8000] loss: 0.013\n",
      "[4, 10000] loss: 0.013\n",
      "[4, 12000] loss: 0.012\n",
      "[4, 14000] loss: 0.012\n",
      "[4, 16000] loss: 0.012\n",
      "[4, 18000] loss: 0.012\n",
      "[4, 20000] loss: 0.012\n",
      "[4, 22000] loss: 0.012\n",
      "[4, 24000] loss: 0.012\n",
      "Epoch 4\n",
      "[5,  2000] loss: 0.012\n",
      "[5,  4000] loss: 0.012\n",
      "[5,  6000] loss: 0.012\n",
      "[5,  8000] loss: 0.012\n",
      "[5, 10000] loss: 0.012\n",
      "[5, 12000] loss: 0.012\n",
      "[5, 14000] loss: 0.011\n",
      "[5, 16000] loss: 0.011\n",
      "[5, 18000] loss: 0.011\n",
      "[5, 20000] loss: 0.011\n",
      "[5, 22000] loss: 0.011\n",
      "[5, 24000] loss: 0.011\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "\n",
    "    for i, (images,_) in enumerate(unlabeledloader):    # Ignore image labels\n",
    "        optimizer.zero_grad()\n",
    "        out, code = autoencoder_for_net(Variable(images))\n",
    "\n",
    "        loss = criterion(out, Variable(images))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  0.002748841746058315\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "counter = 0\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    counter += 4\n",
    "    outputs, _ = autoencoder_for_net(Variable(images))\n",
    "    total += criterion(outputs, Variable(images)).data[0]\n",
    "print('Test loss = ', total / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=4, \\\n",
    "                  conv1_out_channels=30, \\\n",
    "                  weight=autoencoder_for_net.conv.weight, \\\n",
    "                  layers_num=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.899\n",
      "[2,  1000] loss: 1.507\n",
      "[3,  1000] loss: 1.338\n",
      "[4,  1000] loss: 1.182\n",
      "[5,  1000] loss: 1.032\n",
      "[6,  1000] loss: 0.886\n",
      "[7,  1000] loss: 0.754\n",
      "[8,  1000] loss: 0.621\n",
      "[9,  1000] loss: 0.490\n",
      "[10,  1000] loss: 0.346\n",
      "[11,  1000] loss: 0.263\n",
      "[12,  1000] loss: 0.209\n",
      "[13,  1000] loss: 0.152\n",
      "[14,  1000] loss: 0.087\n",
      "[15,  1000] loss: 0.122\n",
      "[16,  1000] loss: 0.062\n",
      "[17,  1000] loss: 0.063\n",
      "[18,  1000] loss: 0.040\n",
      "[19,  1000] loss: 0.063\n",
      "[20,  1000] loss: 0.061\n",
      "[21,  1000] loss: 0.069\n",
      "[22,  1000] loss: 0.065\n",
      "[23,  1000] loss: 0.008\n",
      "[24,  1000] loss: 0.002\n",
      "[25,  1000] loss: 0.001\n",
      "[26,  1000] loss: 0.001\n",
      "[27,  1000] loss: 0.001\n",
      "[28,  1000] loss: 0.001\n",
      "[29,  1000] loss: 0.001\n",
      "[30,  1000] loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 80000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "            100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать больше итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoEncoder(\n",
      "  (conv): Conv2d (3, 30, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (transpose): ConvTranspose2d (30, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder_for_net = ConvAutoEncoder(conv_out_channels=30, conv_padding=1, conv_kernel_size=2 * (1 + 1))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(autoencoder_for_net.parameters(), lr=0.001, momentum=0.99, weight_decay=1e-4)\n",
    "print(autoencoder_for_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[1,  2000] loss: 0.041\n",
      "[1,  4000] loss: 0.018\n",
      "[1,  6000] loss: 0.014\n",
      "[1,  8000] loss: 0.013\n",
      "[1, 10000] loss: 0.012\n",
      "[1, 12000] loss: 0.011\n",
      "[1, 14000] loss: 0.011\n",
      "[1, 16000] loss: 0.010\n",
      "[1, 18000] loss: 0.010\n",
      "[1, 20000] loss: 0.010\n",
      "[1, 22000] loss: 0.010\n",
      "[1, 24000] loss: 0.009\n",
      "Epoch 1\n",
      "[2,  2000] loss: 0.009\n",
      "[2,  4000] loss: 0.009\n",
      "[2,  6000] loss: 0.009\n",
      "[2,  8000] loss: 0.009\n",
      "[2, 10000] loss: 0.009\n",
      "[2, 12000] loss: 0.009\n",
      "[2, 14000] loss: 0.009\n",
      "[2, 16000] loss: 0.008\n",
      "[2, 18000] loss: 0.008\n",
      "[2, 20000] loss: 0.008\n",
      "[2, 22000] loss: 0.008\n",
      "[2, 24000] loss: 0.008\n",
      "Epoch 2\n",
      "[3,  2000] loss: 0.008\n",
      "[3,  4000] loss: 0.008\n",
      "[3,  6000] loss: 0.008\n",
      "[3,  8000] loss: 0.008\n",
      "[3, 10000] loss: 0.008\n",
      "[3, 12000] loss: 0.008\n",
      "[3, 14000] loss: 0.008\n",
      "[3, 16000] loss: 0.008\n",
      "[3, 18000] loss: 0.008\n",
      "[3, 20000] loss: 0.008\n",
      "[3, 22000] loss: 0.008\n",
      "[3, 24000] loss: 0.008\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "\n",
    "    for i, (images,_) in enumerate(unlabeledloader):    # Ignore image labels\n",
    "        optimizer.zero_grad()\n",
    "        out, code = autoencoder_for_net(Variable(images))\n",
    "\n",
    "        loss = criterion(out, Variable(images))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  0.0019469866850879043\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "counter = 0\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    counter += 4\n",
    "    outputs, _ = autoencoder_for_net(Variable(images))\n",
    "    total += criterion(outputs, Variable(images)).data[0]\n",
    "print('Test loss = ', total / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(conv)\n",
    "from conv import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = ConvNet(conv1_kernel_size=4, \\\n",
    "                  conv1_out_channels=30, \\\n",
    "                  weight=autoencoder_for_net.conv.weight, \\\n",
    "                  layers_num=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.897\n",
      "[2,  1000] loss: 1.532\n",
      "[3,  1000] loss: 1.336\n",
      "[4,  1000] loss: 1.190\n",
      "[5,  1000] loss: 1.018\n",
      "[6,  1000] loss: 0.884\n",
      "[7,  1000] loss: 0.734\n",
      "[8,  1000] loss: 0.590\n",
      "[9,  1000] loss: 0.453\n",
      "[10,  1000] loss: 0.343\n",
      "[11,  1000] loss: 0.237\n",
      "[12,  1000] loss: 0.151\n",
      "[13,  1000] loss: 0.106\n",
      "[14,  1000] loss: 0.088\n",
      "[15,  1000] loss: 0.057\n",
      "[16,  1000] loss: 0.086\n",
      "[17,  1000] loss: 0.043\n",
      "[18,  1000] loss: 0.065\n",
      "[19,  1000] loss: 0.094\n",
      "[20,  1000] loss: 0.032\n",
      "[21,  1000] loss: 0.024\n",
      "[22,  1000] loss: 0.034\n",
      "[23,  1000] loss: 0.024\n",
      "[24,  1000] loss: 0.011\n",
      "[25,  1000] loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.0, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 80000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 80000 test images: %d %%' % (\n",
    "            100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
